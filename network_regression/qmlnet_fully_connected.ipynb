{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy.stats import reciprocal\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import (Input, Convolution1D, Dense, MaxPooling1D,MaxPooling2D,AveragePooling2D,\n",
    "                                    Flatten, Dropout, Activation, average,\n",
    "                                    BatchNormalization, Reshape, Conv2D)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from keras import backend as K\n",
    "#scoring=make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X           = np.load(\"rep.npy\", allow_pickle=True)\n",
    "energy      = np.load(\"energy.npy\", allow_pickle=True)\n",
    "X_training  = X[:1000]\n",
    "Y_training  = energy[:1000]\n",
    "X_test      = X[-1000:]\n",
    "Y_test      = energy[-1000:]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_model(optimizer, dense_nparams, lr, decay, LAMBDA): #, ):\n",
    "    #filters = 50\n",
    "    if K.backend() == 'tensorflow':\n",
    "        K.clear_session()\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    init = 'he_normal'\n",
    "    \n",
    "    \n",
    "    regu = tf.keras.regularizers.l2(LAMBDA)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(276, input_dim=276, kernel_initializer=init,kernel_regularizer=regu ,activation='linear'))\n",
    "    #276 = 12 x 23 \n",
    "    BatchNormalization()\n",
    "    \n",
    "    #BatchNormalization()\n",
    "    #model.add(exponential_layer)\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    #Dropout(rate=0.8)\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    #Dropout(rate=0.5)\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    #Dropout(rate=0.4)\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    #Dropout(rate=0.1)\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='selu'))\n",
    "    BatchNormalization()\n",
    "    #Dropout(rate=0.1)\n",
    "    model.add(Dense(dense_nparams, kernel_initializer=init, activation='linear'))\n",
    "    model.add(Dense(1, activation='linear', name='Output_Energy'))\n",
    "\n",
    "    opt = Adam(lr=lr ,decay=decay)\n",
    "    model.compile(loss='mae', optimizer=opt)\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "my_callbacks =  [keras.callbacks.EarlyStopping(patience=100), keras.callbacks.TerminateOnNaN(), keras.callbacks.ModelCheckpoint(\"./ml_data/model.h5\", save_best_only=True) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kears_estimator = KerasRegressor(build_fn=create_model , epochs=2500,  batch_size=25, verbose=2)\n",
    "\n",
    "\n",
    "\n",
    "#param_grid = {\n",
    "#    'dense_nparams': [400, 500, 600, 700],\n",
    "#    'optimizer':['Adam'], 'lr': reciprocal(1e-6, 1e-2), 'decay': reciprocal(1e-5,1e-2), 'LAMBDA':  [1e-8, 1e-7], 'filters':  [2, 5, 10, 50 ], 'kernel_size':[3, 5, 10, 20, 50] }\n",
    "\n",
    "\n",
    "#param_grid = {\n",
    "#    'dense_nparams': [400, 500, 600, 700],\n",
    "#    'optimizer':['Adam'], 'lr': [1e-6, 1e-2], 'decay': [1e-5,1e-2], 'LAMBDA':  [1e-8, 1e-7], 'filters':  [2, 5, 10, 50 ], 'kernel_size':[3, 5, 10, 20, 50] }\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'dense_nparams': [3000, 3250],\n",
    "    'optimizer':['Adam'], 'lr': [0.00055, 0.0006,0.00065,0.00075 ], 'decay': [0.008, 0.005, 0.004, 0.003, 0.0025,0.002,0.001, 0.0007, 0.0005, 0.00025], 'LAMBDA':  [1e-9,1e-8, 1e-7, 1e-6] }\n",
    "#out_57:Best: -14.518220 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.0025, 'LAMBDA': 1e-0\n",
    "\n",
    "kfold_splits = 5\n",
    "\n",
    "#RandomizedSearchCV\n",
    "\n",
    "#search = GridSearchCV(estimator=kears_estimator,  param_grid=param_grid,cv=kfold_splits, verbose=1)\n",
    "#search  = RandomizedSearchCV(estimator=kears_estimator, param_distributions=param_grid, n_iter=10, cv=kfold_splits,scorer=scoring,  scoring='neg_mean_absolute_error', verbose=10)\n",
    "#search  = RandomizedSearchCV(estimator=kears_estimator, param_distributions=param_grid, n_iter=10, cv=kfold_splits,scoring=scoring, verbose=10)\n",
    "search  = RandomizedSearchCV(estimator=kears_estimator, param_distributions=param_grid, n_iter=10, cv=kfold_splits, verbose=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_callbacks =  [keras.callbacks.EarlyStopping(patience=100), keras.callbacks.TerminateOnNaN() ]\n",
    "#https://medium.com/@am.benatmane/keras-hyperparameter-tuning-using-sklearn-pipelines-grid-search-with-cross-validation-ccfc74b0ce9f\n",
    "\n",
    "grid_result = search.fit(X_training, Y_training, callbacks= my_callbacks,validation_data=(X_test, Y_test) ) \n",
    "\n",
    "#,n_jobs=-1\n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print (\"rest\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the following hyperparameters to perform well with this network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             -14.518220 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.0025, 'LAMBDA': 1e-0\n",
    "out_29:Best: -14.927439 using {'optimizer': 'RMSprop', 'lr': 0.00075, 'dense_nparams': 3000, 'decay': 0.002, 'LAMBDA': 1e-06}\n",
    "out_38:Best: -14.959991 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.002, 'LAMBDA': 1e-09}\n",
    "out_40:Best: -14.744321 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3250, 'decay': 0.0007, 'LAMBDA': 1e-06}\n",
    "out_50:Best: -14.992078 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.0025, 'LAMBDA': 1e-07}\n",
    "out_53:Best: -14.988046 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.002, 'LAMBDA': 1e-06}\n",
    "out_57:Best: -14.518220 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.0025, 'LAMBDA': 1e-06}\n",
    "out_61:Best: -14.798697 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3000, 'decay': 0.002, 'LAMBDA': 1e-07}\n",
    "**out_62:Best: -14.446813 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3250, 'decay': 0.001, 'LAMBDA': 1e-07}**\n",
    "out_64:Best: -14.874572 using {'optimizer': 'Adam', 'lr': 0.00075, 'dense_nparams': 3000, 'decay': 0.002, 'LAMBDA': 1e-08}\n",
    "out_66:Best: -14.908051 using {'optimizer': 'Adam', 'lr': 0.00075, 'dense_nparams': 3000, 'decay': 0.002, 'LAMBDA': 1e-09}\n",
    "out_67:Best: -14.645539 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3000, 'decay': 0.0007, 'LAMBDA': 1e-09}\n",
    "out_68:Best: -14.875695 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.002, 'LAMBDA': 1e-09}\n",
    "out_69:Best: -14.528221 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3250, 'decay': 0.0007, 'LAMBDA': 1e-09}\n",
    "out_73:Best: -14.848996 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3250, 'decay': 0.002, 'LAMBDA': 1e-07}\n",
    "out_74:Best: -14.613671 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3250, 'decay': 0.001, 'LAMBDA': 1e-06}\n",
    "out_75:Best: -14.840783 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3250, 'decay': 0.002, 'LAMBDA': 1e-06}\n",
    "out_77:Best: -14.818040 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3000, 'decay': 0.0005, 'LAMBDA': 1e-06}\n",
    "out_78:Best: -14.921816 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3250, 'decay': 0.003, 'LAMBDA': 1e-07}\n",
    "out_80:Best: -14.774423 using {'optimizer': 'Adam', 'lr': 0.00075, 'dense_nparams': 3000, 'decay': 0.0025, 'LAMBDA': 1e-09}\n",
    "out_81:Best: -14.997505 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3250, 'decay': 0.001, 'LAMBDA': 1e-06}\n",
    "out_83:Best: -14.653083 using {'optimizer': 'Adam', 'lr': 0.0006, 'dense_nparams': 3000, 'decay': 0.0025, 'LAMBDA': 1e-06}\n",
    "out_84:Best: -14.812062 using {'optimizer': 'Adam', 'lr': 0.00065, 'dense_nparams': 3250, 'decay': 0.001, 'LAMBDA': 1e-06}\n",
    "out_85:Best: -14.838064 using {'optimizer': 'Adam', 'lr': 0.00065, 'dense_nparams': 3250, 'decay': 0.001, 'LAMBDA': 1e-06}\n",
    "out_87:Best: -14.971521 using {'optimizer': 'Adam', 'lr': 0.00075, 'dense_nparams': 3000, 'decay': 0.003, 'LAMBDA': 1e-06}\n",
    "out_91:Best: -14.599177 using {'optimizer': 'Adam', 'lr': 0.00075, 'dense_nparams': 3250, 'decay': 0.0025, 'LAMBDA': 1e-07}\n",
    "out_92:Best: -14.734776 using {'optimizer': 'Adam', 'lr': 0.00055, 'dense_nparams': 3250, 'decay': 0.003, 'LAMBDA': 1e-07}\n",
    "out_96:Best: -14.947271 using {'optimizer': 'Adam', 'lr': 0.00065, 'dense_nparams': 3000, 'decay': 0.003, 'LAMBDA': 1e-06}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single evaluation of the network with the best hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model  = create_model('Adam', 3250, 0.0006, 0.001, 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "40/40 - 3s - loss: 1262.4004 - val_loss: 118.4836\n",
      "Epoch 2/2500\n",
      "40/40 - 2s - loss: 119.7866 - val_loss: 154.2724\n",
      "Epoch 3/2500\n",
      "40/40 - 3s - loss: 136.1271 - val_loss: 62.2950\n",
      "Epoch 4/2500\n",
      "40/40 - 3s - loss: 87.7233 - val_loss: 54.5145\n",
      "Epoch 5/2500\n",
      "40/40 - 2s - loss: 58.8853 - val_loss: 56.4708\n",
      "Epoch 6/2500\n",
      "40/40 - 2s - loss: 53.8051 - val_loss: 66.6191\n",
      "Epoch 7/2500\n",
      "40/40 - 4s - loss: 49.2758 - val_loss: 38.1463\n",
      "Epoch 8/2500\n",
      "40/40 - 4s - loss: 51.8163 - val_loss: 36.3315\n",
      "Epoch 9/2500\n",
      "40/40 - 2s - loss: 59.2048 - val_loss: 59.1255\n",
      "Epoch 10/2500\n",
      "40/40 - 4s - loss: 40.3884 - val_loss: 30.8706\n",
      "Epoch 11/2500\n",
      "40/40 - 4s - loss: 41.2027 - val_loss: 27.9861\n",
      "Epoch 12/2500\n",
      "40/40 - 2s - loss: 54.2390 - val_loss: 62.0120\n",
      "Epoch 13/2500\n",
      "40/40 - 2s - loss: 42.8498 - val_loss: 34.1948\n",
      "Epoch 14/2500\n",
      "40/40 - 4s - loss: 34.3615 - val_loss: 27.8124\n",
      "Epoch 15/2500\n",
      "40/40 - 2s - loss: 38.6908 - val_loss: 31.7076\n",
      "Epoch 16/2500\n",
      "40/40 - 2s - loss: 36.9424 - val_loss: 35.6682\n",
      "Epoch 17/2500\n",
      "40/40 - 2s - loss: 37.1953 - val_loss: 39.2196\n",
      "Epoch 18/2500\n",
      "40/40 - 3s - loss: 34.7555 - val_loss: 26.4498\n",
      "Epoch 19/2500\n",
      "40/40 - 2s - loss: 28.4933 - val_loss: 29.5170\n",
      "Epoch 20/2500\n",
      "40/40 - 2s - loss: 30.7660 - val_loss: 36.1376\n",
      "Epoch 21/2500\n",
      "40/40 - 2s - loss: 25.6250 - val_loss: 29.9804\n",
      "Epoch 22/2500\n",
      "40/40 - 2s - loss: 30.4690 - val_loss: 46.4308\n",
      "Epoch 23/2500\n",
      "40/40 - 2s - loss: 29.9697 - val_loss: 27.3938\n",
      "Epoch 24/2500\n",
      "40/40 - 4s - loss: 24.5773 - val_loss: 23.1281\n",
      "Epoch 25/2500\n",
      "40/40 - 2s - loss: 25.7828 - val_loss: 23.9348\n",
      "Epoch 26/2500\n",
      "40/40 - 2s - loss: 27.2793 - val_loss: 24.5461\n",
      "Epoch 27/2500\n",
      "40/40 - 2s - loss: 26.3769 - val_loss: 24.2003\n",
      "Epoch 28/2500\n",
      "40/40 - 4s - loss: 23.0404 - val_loss: 21.1882\n",
      "Epoch 29/2500\n",
      "40/40 - 3s - loss: 28.4963 - val_loss: 20.8672\n",
      "Epoch 30/2500\n",
      "40/40 - 4s - loss: 24.8380 - val_loss: 18.5401\n",
      "Epoch 31/2500\n",
      "40/40 - 2s - loss: 21.0484 - val_loss: 27.6671\n",
      "Epoch 32/2500\n",
      "40/40 - 2s - loss: 19.5538 - val_loss: 22.5089\n",
      "Epoch 33/2500\n",
      "40/40 - 2s - loss: 23.7720 - val_loss: 30.4958\n",
      "Epoch 34/2500\n",
      "40/40 - 2s - loss: 29.8640 - val_loss: 58.9477\n",
      "Epoch 35/2500\n",
      "40/40 - 2s - loss: 42.1644 - val_loss: 47.8437\n",
      "Epoch 36/2500\n",
      "40/40 - 2s - loss: 19.3320 - val_loss: 18.8017\n",
      "Epoch 37/2500\n",
      "40/40 - 2s - loss: 21.9673 - val_loss: 22.5791\n",
      "Epoch 38/2500\n",
      "40/40 - 4s - loss: 25.9888 - val_loss: 17.3733\n",
      "Epoch 39/2500\n",
      "40/40 - 2s - loss: 18.0900 - val_loss: 19.8059\n",
      "Epoch 40/2500\n",
      "40/40 - 2s - loss: 18.9919 - val_loss: 23.6628\n",
      "Epoch 41/2500\n",
      "40/40 - 2s - loss: 18.6423 - val_loss: 20.4408\n",
      "Epoch 42/2500\n",
      "40/40 - 2s - loss: 21.2069 - val_loss: 21.0065\n",
      "Epoch 43/2500\n",
      "40/40 - 2s - loss: 16.1386 - val_loss: 20.0022\n",
      "Epoch 44/2500\n",
      "40/40 - 2s - loss: 18.4415 - val_loss: 19.0279\n",
      "Epoch 45/2500\n",
      "40/40 - 2s - loss: 17.6778 - val_loss: 19.5957\n",
      "Epoch 46/2500\n",
      "40/40 - 2s - loss: 22.5375 - val_loss: 29.5781\n",
      "Epoch 47/2500\n",
      "40/40 - 3s - loss: 17.5933 - val_loss: 17.0665\n",
      "Epoch 48/2500\n",
      "40/40 - 2s - loss: 13.4466 - val_loss: 19.2386\n",
      "Epoch 49/2500\n",
      "40/40 - 2s - loss: 14.0623 - val_loss: 21.3358\n",
      "Epoch 50/2500\n",
      "40/40 - 2s - loss: 17.3953 - val_loss: 17.7558\n",
      "Epoch 51/2500\n",
      "40/40 - 2s - loss: 13.6001 - val_loss: 20.2077\n",
      "Epoch 52/2500\n",
      "40/40 - 3s - loss: 15.7379 - val_loss: 15.8267\n",
      "Epoch 53/2500\n",
      "40/40 - 2s - loss: 15.7882 - val_loss: 22.5880\n",
      "Epoch 54/2500\n",
      "40/40 - 2s - loss: 16.1877 - val_loss: 20.8723\n",
      "Epoch 55/2500\n",
      "40/40 - 2s - loss: 12.5514 - val_loss: 25.2820\n",
      "Epoch 56/2500\n",
      "40/40 - 2s - loss: 24.2638 - val_loss: 31.6127\n",
      "Epoch 57/2500\n",
      "40/40 - 2s - loss: 16.4555 - val_loss: 20.6362\n",
      "Epoch 58/2500\n",
      "40/40 - 2s - loss: 13.7761 - val_loss: 20.5820\n",
      "Epoch 59/2500\n",
      "40/40 - 4s - loss: 11.8762 - val_loss: 15.6376\n",
      "Epoch 60/2500\n",
      "40/40 - 2s - loss: 14.8576 - val_loss: 16.7921\n",
      "Epoch 61/2500\n",
      "40/40 - 2s - loss: 12.0901 - val_loss: 16.4518\n",
      "Epoch 62/2500\n",
      "40/40 - 2s - loss: 14.0441 - val_loss: 18.2264\n",
      "Epoch 63/2500\n",
      "40/40 - 2s - loss: 12.1927 - val_loss: 17.0207\n",
      "Epoch 64/2500\n",
      "40/40 - 2s - loss: 17.3921 - val_loss: 17.7424\n",
      "Epoch 65/2500\n",
      "40/40 - 2s - loss: 14.8258 - val_loss: 21.6218\n",
      "Epoch 66/2500\n",
      "40/40 - 4s - loss: 13.4572 - val_loss: 15.0179\n",
      "Epoch 67/2500\n",
      "40/40 - 2s - loss: 12.6171 - val_loss: 19.3844\n",
      "Epoch 68/2500\n",
      "40/40 - 2s - loss: 13.5512 - val_loss: 19.7796\n",
      "Epoch 69/2500\n",
      "40/40 - 2s - loss: 17.0210 - val_loss: 18.1658\n",
      "Epoch 70/2500\n",
      "40/40 - 2s - loss: 13.7157 - val_loss: 18.7147\n",
      "Epoch 71/2500\n",
      "40/40 - 2s - loss: 12.6193 - val_loss: 20.9104\n",
      "Epoch 72/2500\n",
      "40/40 - 2s - loss: 15.5445 - val_loss: 27.4037\n",
      "Epoch 73/2500\n",
      "40/40 - 2s - loss: 13.4330 - val_loss: 15.4592\n",
      "Epoch 74/2500\n",
      "40/40 - 2s - loss: 12.9086 - val_loss: 21.9135\n",
      "Epoch 75/2500\n",
      "40/40 - 2s - loss: 12.9312 - val_loss: 15.6203\n",
      "Epoch 76/2500\n",
      "40/40 - 2s - loss: 11.5498 - val_loss: 19.3215\n",
      "Epoch 77/2500\n",
      "40/40 - 2s - loss: 12.3776 - val_loss: 15.9194\n",
      "Epoch 78/2500\n",
      "40/40 - 2s - loss: 11.8240 - val_loss: 17.2278\n",
      "Epoch 79/2500\n",
      "40/40 - 2s - loss: 9.7666 - val_loss: 15.3860\n",
      "Epoch 80/2500\n",
      "40/40 - 2s - loss: 11.7799 - val_loss: 19.1430\n",
      "Epoch 81/2500\n",
      "40/40 - 2s - loss: 13.2784 - val_loss: 17.8144\n",
      "Epoch 82/2500\n",
      "40/40 - 2s - loss: 11.2041 - val_loss: 17.8647\n",
      "Epoch 83/2500\n",
      "40/40 - 2s - loss: 11.7227 - val_loss: 20.5086\n",
      "Epoch 84/2500\n",
      "40/40 - 3s - loss: 11.6507 - val_loss: 14.8671\n",
      "Epoch 85/2500\n",
      "40/40 - 2s - loss: 15.4952 - val_loss: 15.3325\n",
      "Epoch 86/2500\n",
      "40/40 - 2s - loss: 10.7964 - val_loss: 16.8843\n",
      "Epoch 87/2500\n",
      "40/40 - 2s - loss: 12.3765 - val_loss: 15.3407\n",
      "Epoch 88/2500\n",
      "40/40 - 2s - loss: 11.8560 - val_loss: 18.5101\n",
      "Epoch 89/2500\n",
      "40/40 - 2s - loss: 10.6816 - val_loss: 16.7889\n",
      "Epoch 90/2500\n",
      "40/40 - 2s - loss: 13.2390 - val_loss: 20.8446\n",
      "Epoch 91/2500\n",
      "40/40 - 2s - loss: 12.2384 - val_loss: 14.9586\n",
      "Epoch 92/2500\n",
      "40/40 - 2s - loss: 10.6023 - val_loss: 20.9427\n",
      "Epoch 93/2500\n",
      "40/40 - 2s - loss: 15.2403 - val_loss: 16.9598\n",
      "Epoch 94/2500\n",
      "40/40 - 2s - loss: 10.1971 - val_loss: 14.8772\n",
      "Epoch 95/2500\n",
      "40/40 - 2s - loss: 15.9492 - val_loss: 19.4247\n",
      "Epoch 96/2500\n",
      "40/40 - 2s - loss: 12.9318 - val_loss: 18.2842\n",
      "Epoch 97/2500\n",
      "40/40 - 2s - loss: 11.5704 - val_loss: 15.9460\n",
      "Epoch 98/2500\n",
      "40/40 - 4s - loss: 10.4112 - val_loss: 14.6532\n",
      "Epoch 99/2500\n",
      "40/40 - 2s - loss: 9.1950 - val_loss: 17.4080\n",
      "Epoch 100/2500\n",
      "40/40 - 3s - loss: 9.1023 - val_loss: 14.4956\n",
      "Epoch 101/2500\n",
      "40/40 - 4s - loss: 7.9097 - val_loss: 14.2685\n",
      "Epoch 102/2500\n",
      "40/40 - 2s - loss: 8.6910 - val_loss: 14.9829\n",
      "Epoch 103/2500\n",
      "40/40 - 2s - loss: 10.3533 - val_loss: 15.4773\n",
      "Epoch 104/2500\n",
      "40/40 - 2s - loss: 13.1598 - val_loss: 21.6611\n",
      "Epoch 105/2500\n",
      "40/40 - 2s - loss: 10.3399 - val_loss: 15.5471\n",
      "Epoch 106/2500\n",
      "40/40 - 4s - loss: 8.5121 - val_loss: 13.8402\n",
      "Epoch 107/2500\n",
      "40/40 - 2s - loss: 7.4446 - val_loss: 16.1324\n",
      "Epoch 108/2500\n",
      "40/40 - 2s - loss: 10.7393 - val_loss: 15.5166\n",
      "Epoch 109/2500\n",
      "40/40 - 2s - loss: 14.8956 - val_loss: 23.0582\n",
      "Epoch 110/2500\n",
      "40/40 - 2s - loss: 12.7074 - val_loss: 16.3563\n",
      "Epoch 111/2500\n",
      "40/40 - 2s - loss: 8.8534 - val_loss: 14.1759\n",
      "Epoch 112/2500\n",
      "40/40 - 2s - loss: 13.2046 - val_loss: 21.6699\n",
      "Epoch 113/2500\n",
      "40/40 - 2s - loss: 9.6211 - val_loss: 19.7325\n",
      "Epoch 114/2500\n",
      "40/40 - 2s - loss: 9.2316 - val_loss: 14.7164\n",
      "Epoch 115/2500\n",
      "40/40 - 2s - loss: 7.9559 - val_loss: 15.5589\n",
      "Epoch 116/2500\n",
      "40/40 - 2s - loss: 10.2955 - val_loss: 15.1824\n",
      "Epoch 117/2500\n",
      "40/40 - 2s - loss: 10.7265 - val_loss: 15.6399\n",
      "Epoch 118/2500\n",
      "40/40 - 2s - loss: 10.6390 - val_loss: 16.2524\n",
      "Epoch 119/2500\n",
      "40/40 - 4s - loss: 8.3461 - val_loss: 13.6318\n",
      "Epoch 120/2500\n",
      "40/40 - 2s - loss: 9.6787 - val_loss: 14.2343\n",
      "Epoch 121/2500\n",
      "40/40 - 2s - loss: 9.3341 - val_loss: 18.6758\n",
      "Epoch 122/2500\n",
      "40/40 - 2s - loss: 8.3050 - val_loss: 16.3564\n",
      "Epoch 123/2500\n",
      "40/40 - 2s - loss: 11.5876 - val_loss: 17.4546\n",
      "Epoch 124/2500\n",
      "40/40 - 2s - loss: 9.8771 - val_loss: 16.5666\n",
      "Epoch 125/2500\n",
      "40/40 - 2s - loss: 9.0381 - val_loss: 14.3709\n",
      "Epoch 126/2500\n",
      "40/40 - 2s - loss: 6.4258 - val_loss: 15.2890\n",
      "Epoch 127/2500\n",
      "40/40 - 2s - loss: 7.8063 - val_loss: 13.9619\n",
      "Epoch 128/2500\n",
      "40/40 - 2s - loss: 6.0988 - val_loss: 14.1926\n",
      "Epoch 129/2500\n",
      "40/40 - 2s - loss: 11.0999 - val_loss: 18.4308\n",
      "Epoch 130/2500\n",
      "40/40 - 2s - loss: 10.3501 - val_loss: 17.9462\n",
      "Epoch 131/2500\n",
      "40/40 - 2s - loss: 7.1084 - val_loss: 14.9122\n",
      "Epoch 132/2500\n",
      "40/40 - 2s - loss: 6.5422 - val_loss: 13.8922\n",
      "Epoch 133/2500\n",
      "40/40 - 2s - loss: 8.2885 - val_loss: 14.1943\n",
      "Epoch 134/2500\n",
      "40/40 - 2s - loss: 6.7774 - val_loss: 14.8340\n",
      "Epoch 135/2500\n",
      "40/40 - 2s - loss: 6.5784 - val_loss: 14.3204\n",
      "Epoch 136/2500\n",
      "40/40 - 2s - loss: 6.7879 - val_loss: 15.3803\n",
      "Epoch 137/2500\n",
      "40/40 - 2s - loss: 9.0562 - val_loss: 18.9247\n",
      "Epoch 138/2500\n",
      "40/40 - 2s - loss: 10.2526 - val_loss: 15.6504\n",
      "Epoch 139/2500\n",
      "40/40 - 2s - loss: 8.5962 - val_loss: 14.0698\n",
      "Epoch 140/2500\n",
      "40/40 - 2s - loss: 8.3949 - val_loss: 15.1304\n",
      "Epoch 141/2500\n",
      "40/40 - 2s - loss: 8.2420 - val_loss: 16.7250\n",
      "Epoch 142/2500\n",
      "40/40 - 2s - loss: 7.6927 - val_loss: 18.6634\n",
      "Epoch 143/2500\n",
      "40/40 - 2s - loss: 10.7749 - val_loss: 14.6257\n",
      "Epoch 144/2500\n",
      "40/40 - 2s - loss: 5.3355 - val_loss: 15.4574\n",
      "Epoch 145/2500\n",
      "40/40 - 2s - loss: 8.6330 - val_loss: 16.1803\n",
      "Epoch 146/2500\n",
      "40/40 - 2s - loss: 7.9872 - val_loss: 15.3709\n",
      "Epoch 147/2500\n",
      "40/40 - 2s - loss: 9.0722 - val_loss: 14.9837\n",
      "Epoch 148/2500\n",
      "40/40 - 2s - loss: 6.5998 - val_loss: 18.2584\n",
      "Epoch 149/2500\n",
      "40/40 - 2s - loss: 7.6069 - val_loss: 17.7066\n",
      "Epoch 150/2500\n",
      "40/40 - 2s - loss: 6.4238 - val_loss: 14.0003\n",
      "Epoch 151/2500\n",
      "40/40 - 2s - loss: 7.5830 - val_loss: 16.8004\n",
      "Epoch 152/2500\n",
      "40/40 - 2s - loss: 9.6489 - val_loss: 13.8329\n",
      "Epoch 153/2500\n",
      "40/40 - 2s - loss: 7.0700 - val_loss: 17.5558\n",
      "Epoch 154/2500\n",
      "40/40 - 2s - loss: 10.5127 - val_loss: 18.9827\n",
      "Epoch 155/2500\n",
      "40/40 - 2s - loss: 9.0329 - val_loss: 14.7177\n",
      "Epoch 156/2500\n",
      "40/40 - 2s - loss: 6.1802 - val_loss: 14.3781\n",
      "Epoch 157/2500\n",
      "40/40 - 2s - loss: 7.7252 - val_loss: 15.2629\n",
      "Epoch 158/2500\n",
      "40/40 - 2s - loss: 8.5521 - val_loss: 14.4484\n",
      "Epoch 159/2500\n",
      "40/40 - 2s - loss: 6.8270 - val_loss: 14.2139\n",
      "Epoch 160/2500\n",
      "40/40 - 2s - loss: 7.5287 - val_loss: 15.2811\n",
      "Epoch 161/2500\n",
      "40/40 - 4s - loss: 6.2096 - val_loss: 13.3920\n",
      "Epoch 162/2500\n",
      "40/40 - 2s - loss: 6.4985 - val_loss: 14.2461\n",
      "Epoch 163/2500\n",
      "40/40 - 2s - loss: 5.9818 - val_loss: 14.9678\n",
      "Epoch 164/2500\n",
      "40/40 - 2s - loss: 5.5398 - val_loss: 14.8009\n",
      "Epoch 165/2500\n",
      "40/40 - 2s - loss: 7.2594 - val_loss: 14.6716\n",
      "Epoch 166/2500\n",
      "40/40 - 2s - loss: 6.5753 - val_loss: 14.8887\n",
      "Epoch 167/2500\n",
      "40/40 - 2s - loss: 5.9605 - val_loss: 14.8752\n",
      "Epoch 168/2500\n",
      "40/40 - 2s - loss: 8.1876 - val_loss: 17.0372\n",
      "Epoch 169/2500\n",
      "40/40 - 4s - loss: 7.1230 - val_loss: 13.2406\n",
      "Epoch 170/2500\n",
      "40/40 - 2s - loss: 7.4809 - val_loss: 14.0231\n",
      "Epoch 171/2500\n",
      "40/40 - 2s - loss: 7.0017 - val_loss: 16.0817\n",
      "Epoch 172/2500\n",
      "40/40 - 2s - loss: 7.8183 - val_loss: 15.6608\n",
      "Epoch 173/2500\n",
      "40/40 - 2s - loss: 5.6566 - val_loss: 13.7905\n",
      "Epoch 174/2500\n",
      "40/40 - 2s - loss: 5.2582 - val_loss: 14.3216\n",
      "Epoch 175/2500\n",
      "40/40 - 2s - loss: 5.2636 - val_loss: 17.9157\n",
      "Epoch 176/2500\n",
      "40/40 - 2s - loss: 6.1892 - val_loss: 13.9573\n",
      "Epoch 177/2500\n",
      "40/40 - 2s - loss: 5.8868 - val_loss: 14.3582\n",
      "Epoch 178/2500\n",
      "40/40 - 2s - loss: 4.7066 - val_loss: 13.9000\n",
      "Epoch 179/2500\n",
      "40/40 - 2s - loss: 4.6765 - val_loss: 13.6180\n",
      "Epoch 180/2500\n",
      "40/40 - 2s - loss: 5.7616 - val_loss: 15.6358\n",
      "Epoch 181/2500\n",
      "40/40 - 2s - loss: 8.3797 - val_loss: 17.0756\n",
      "Epoch 182/2500\n",
      "40/40 - 2s - loss: 7.5229 - val_loss: 16.0312\n",
      "Epoch 183/2500\n",
      "40/40 - 2s - loss: 7.3066 - val_loss: 14.2507\n",
      "Epoch 184/2500\n",
      "40/40 - 2s - loss: 4.8465 - val_loss: 14.5660\n",
      "Epoch 185/2500\n",
      "40/40 - 2s - loss: 6.6309 - val_loss: 14.2227\n",
      "Epoch 186/2500\n",
      "40/40 - 2s - loss: 7.2606 - val_loss: 15.4080\n",
      "Epoch 187/2500\n",
      "40/40 - 2s - loss: 9.7542 - val_loss: 14.8705\n",
      "Epoch 188/2500\n",
      "40/40 - 2s - loss: 7.0902 - val_loss: 15.1581\n",
      "Epoch 189/2500\n",
      "40/40 - 2s - loss: 5.7471 - val_loss: 14.0576\n",
      "Epoch 190/2500\n",
      "40/40 - 2s - loss: 5.5094 - val_loss: 14.1964\n",
      "Epoch 191/2500\n",
      "40/40 - 2s - loss: 6.9646 - val_loss: 13.8616\n",
      "Epoch 192/2500\n",
      "40/40 - 2s - loss: 5.1379 - val_loss: 14.1397\n",
      "Epoch 193/2500\n",
      "40/40 - 2s - loss: 5.3384 - val_loss: 13.7943\n",
      "Epoch 194/2500\n",
      "40/40 - 2s - loss: 5.9055 - val_loss: 15.0196\n",
      "Epoch 195/2500\n",
      "40/40 - 2s - loss: 5.5025 - val_loss: 14.5923\n",
      "Epoch 196/2500\n",
      "40/40 - 2s - loss: 5.1212 - val_loss: 14.7289\n",
      "Epoch 197/2500\n",
      "40/40 - 2s - loss: 7.8199 - val_loss: 17.7001\n",
      "Epoch 198/2500\n",
      "40/40 - 2s - loss: 5.9546 - val_loss: 13.5440\n",
      "Epoch 199/2500\n",
      "40/40 - 2s - loss: 4.7489 - val_loss: 14.1663\n",
      "Epoch 200/2500\n",
      "40/40 - 2s - loss: 5.2381 - val_loss: 13.8181\n",
      "Epoch 201/2500\n",
      "40/40 - 2s - loss: 5.0732 - val_loss: 13.9083\n",
      "Epoch 202/2500\n",
      "40/40 - 2s - loss: 4.4331 - val_loss: 13.8383\n",
      "Epoch 203/2500\n",
      "40/40 - 2s - loss: 5.5697 - val_loss: 13.9645\n",
      "Epoch 204/2500\n",
      "40/40 - 2s - loss: 5.8405 - val_loss: 14.0993\n",
      "Epoch 205/2500\n",
      "40/40 - 2s - loss: 9.0950 - val_loss: 16.2089\n",
      "Epoch 206/2500\n",
      "40/40 - 4s - loss: 5.3930 - val_loss: 13.1791\n",
      "Epoch 207/2500\n",
      "40/40 - 2s - loss: 4.6620 - val_loss: 13.8053\n",
      "Epoch 208/2500\n",
      "40/40 - 2s - loss: 6.7574 - val_loss: 13.5207\n",
      "Epoch 209/2500\n",
      "40/40 - 2s - loss: 3.9800 - val_loss: 14.3703\n",
      "Epoch 210/2500\n",
      "40/40 - 2s - loss: 4.6177 - val_loss: 13.6238\n",
      "Epoch 211/2500\n",
      "40/40 - 2s - loss: 5.5376 - val_loss: 14.3339\n",
      "Epoch 212/2500\n",
      "40/40 - 2s - loss: 4.7478 - val_loss: 14.1391\n",
      "Epoch 213/2500\n",
      "40/40 - 2s - loss: 5.4817 - val_loss: 15.7731\n",
      "Epoch 214/2500\n",
      "40/40 - 2s - loss: 8.2197 - val_loss: 13.9410\n",
      "Epoch 215/2500\n",
      "40/40 - 2s - loss: 4.2946 - val_loss: 13.6062\n",
      "Epoch 216/2500\n",
      "40/40 - 2s - loss: 5.3327 - val_loss: 14.4739\n",
      "Epoch 217/2500\n",
      "40/40 - 2s - loss: 5.7272 - val_loss: 13.6614\n",
      "Epoch 218/2500\n",
      "40/40 - 2s - loss: 7.1662 - val_loss: 20.3756\n",
      "Epoch 219/2500\n",
      "40/40 - 2s - loss: 7.6602 - val_loss: 13.9144\n",
      "Epoch 220/2500\n",
      "40/40 - 2s - loss: 5.2152 - val_loss: 14.0154\n",
      "Epoch 221/2500\n",
      "40/40 - 2s - loss: 5.1193 - val_loss: 15.0049\n",
      "Epoch 222/2500\n",
      "40/40 - 2s - loss: 4.8131 - val_loss: 13.9140\n",
      "Epoch 223/2500\n",
      "40/40 - 2s - loss: 4.2067 - val_loss: 13.7237\n",
      "Epoch 224/2500\n",
      "40/40 - 2s - loss: 6.4900 - val_loss: 16.3076\n",
      "Epoch 225/2500\n",
      "40/40 - 2s - loss: 7.2516 - val_loss: 15.1485\n",
      "Epoch 226/2500\n",
      "40/40 - 2s - loss: 4.3458 - val_loss: 13.8246\n",
      "Epoch 227/2500\n",
      "40/40 - 2s - loss: 4.9597 - val_loss: 13.7257\n",
      "Epoch 228/2500\n",
      "40/40 - 2s - loss: 3.7224 - val_loss: 13.6387\n",
      "Epoch 229/2500\n",
      "40/40 - 2s - loss: 4.5925 - val_loss: 14.1473\n",
      "Epoch 230/2500\n",
      "40/40 - 2s - loss: 4.3120 - val_loss: 13.6995\n",
      "Epoch 231/2500\n",
      "40/40 - 2s - loss: 5.7435 - val_loss: 14.2154\n",
      "Epoch 232/2500\n",
      "40/40 - 2s - loss: 4.3469 - val_loss: 14.0495\n",
      "Epoch 233/2500\n",
      "40/40 - 2s - loss: 4.8815 - val_loss: 14.8689\n",
      "Epoch 234/2500\n",
      "40/40 - 2s - loss: 6.5700 - val_loss: 15.8157\n",
      "Epoch 235/2500\n",
      "40/40 - 2s - loss: 7.8395 - val_loss: 14.1874\n",
      "Epoch 236/2500\n",
      "40/40 - 2s - loss: 4.8533 - val_loss: 15.4801\n",
      "Epoch 237/2500\n",
      "40/40 - 2s - loss: 6.1592 - val_loss: 13.8488\n",
      "Epoch 238/2500\n",
      "40/40 - 2s - loss: 4.6728 - val_loss: 13.8672\n",
      "Epoch 239/2500\n",
      "40/40 - 2s - loss: 4.0826 - val_loss: 13.6563\n",
      "Epoch 240/2500\n",
      "40/40 - 2s - loss: 5.2096 - val_loss: 13.2312\n",
      "Epoch 241/2500\n",
      "40/40 - 2s - loss: 4.1170 - val_loss: 14.1065\n",
      "Epoch 242/2500\n",
      "40/40 - 2s - loss: 4.6594 - val_loss: 13.6159\n",
      "Epoch 243/2500\n",
      "40/40 - 2s - loss: 3.9496 - val_loss: 13.8185\n",
      "Epoch 244/2500\n",
      "40/40 - 2s - loss: 5.2642 - val_loss: 13.7323\n",
      "Epoch 245/2500\n",
      "40/40 - 2s - loss: 5.5148 - val_loss: 14.5534\n",
      "Epoch 246/2500\n",
      "40/40 - 2s - loss: 5.3939 - val_loss: 14.1585\n",
      "Epoch 247/2500\n",
      "40/40 - 2s - loss: 4.0385 - val_loss: 14.0561\n",
      "Epoch 248/2500\n",
      "40/40 - 2s - loss: 4.3329 - val_loss: 14.0838\n",
      "Epoch 249/2500\n",
      "40/40 - 2s - loss: 4.4586 - val_loss: 13.8699\n",
      "Epoch 250/2500\n",
      "40/40 - 2s - loss: 5.5727 - val_loss: 13.7270\n",
      "Epoch 251/2500\n",
      "40/40 - 2s - loss: 3.6799 - val_loss: 13.8170\n",
      "Epoch 252/2500\n",
      "40/40 - 2s - loss: 5.0772 - val_loss: 13.5198\n",
      "Epoch 253/2500\n",
      "40/40 - 2s - loss: 3.4417 - val_loss: 13.7617\n",
      "Epoch 254/2500\n",
      "40/40 - 2s - loss: 4.7889 - val_loss: 14.9897\n",
      "Epoch 255/2500\n",
      "40/40 - 2s - loss: 4.9819 - val_loss: 13.6561\n",
      "Epoch 256/2500\n",
      "40/40 - 2s - loss: 3.6675 - val_loss: 15.0179\n",
      "Epoch 257/2500\n",
      "40/40 - 2s - loss: 5.1699 - val_loss: 13.5740\n",
      "Epoch 258/2500\n",
      "40/40 - 4s - loss: 3.6783 - val_loss: 13.1228\n",
      "Epoch 259/2500\n",
      "40/40 - 2s - loss: 4.3137 - val_loss: 13.7752\n",
      "Epoch 260/2500\n",
      "40/40 - 2s - loss: 3.5745 - val_loss: 14.1126\n",
      "Epoch 261/2500\n",
      "40/40 - 2s - loss: 4.7189 - val_loss: 14.8216\n",
      "Epoch 262/2500\n",
      "40/40 - 2s - loss: 4.5747 - val_loss: 13.6462\n",
      "Epoch 263/2500\n",
      "40/40 - 2s - loss: 4.5420 - val_loss: 16.7990\n",
      "Epoch 264/2500\n",
      "40/40 - 2s - loss: 5.3863 - val_loss: 13.4701\n",
      "Epoch 265/2500\n",
      "40/40 - 2s - loss: 4.2160 - val_loss: 14.4337\n",
      "Epoch 266/2500\n",
      "40/40 - 2s - loss: 3.8603 - val_loss: 13.9567\n",
      "Epoch 267/2500\n",
      "40/40 - 2s - loss: 4.0296 - val_loss: 13.5415\n",
      "Epoch 268/2500\n",
      "40/40 - 2s - loss: 4.0609 - val_loss: 13.7112\n",
      "Epoch 269/2500\n",
      "40/40 - 2s - loss: 3.6696 - val_loss: 13.6863\n",
      "Epoch 270/2500\n",
      "40/40 - 2s - loss: 3.1655 - val_loss: 14.0996\n",
      "Epoch 271/2500\n",
      "40/40 - 2s - loss: 6.4995 - val_loss: 14.7158\n",
      "Epoch 272/2500\n",
      "40/40 - 2s - loss: 5.7259 - val_loss: 14.7159\n",
      "Epoch 273/2500\n",
      "40/40 - 2s - loss: 5.2723 - val_loss: 15.7394\n",
      "Epoch 274/2500\n",
      "40/40 - 2s - loss: 4.9603 - val_loss: 14.6128\n",
      "Epoch 275/2500\n",
      "40/40 - 2s - loss: 5.2311 - val_loss: 14.4463\n",
      "Epoch 276/2500\n",
      "40/40 - 2s - loss: 5.3723 - val_loss: 14.1348\n",
      "Epoch 277/2500\n",
      "40/40 - 2s - loss: 5.3812 - val_loss: 13.3525\n",
      "Epoch 278/2500\n",
      "40/40 - 2s - loss: 3.2887 - val_loss: 13.7746\n",
      "Epoch 279/2500\n",
      "40/40 - 2s - loss: 4.0112 - val_loss: 13.7579\n",
      "Epoch 280/2500\n",
      "40/40 - 2s - loss: 4.1922 - val_loss: 13.6224\n",
      "Epoch 281/2500\n",
      "40/40 - 2s - loss: 3.0735 - val_loss: 13.6094\n",
      "Epoch 282/2500\n",
      "40/40 - 2s - loss: 4.0085 - val_loss: 13.7056\n",
      "Epoch 283/2500\n",
      "40/40 - 2s - loss: 4.1807 - val_loss: 13.6690\n",
      "Epoch 284/2500\n",
      "40/40 - 2s - loss: 4.2253 - val_loss: 13.9773\n",
      "Epoch 285/2500\n",
      "40/40 - 2s - loss: 3.1620 - val_loss: 13.5381\n",
      "Epoch 286/2500\n",
      "40/40 - 2s - loss: 2.8993 - val_loss: 14.0959\n",
      "Epoch 287/2500\n",
      "40/40 - 2s - loss: 4.1887 - val_loss: 16.5671\n",
      "Epoch 288/2500\n",
      "40/40 - 2s - loss: 5.5662 - val_loss: 13.3591\n",
      "Epoch 289/2500\n",
      "40/40 - 2s - loss: 3.3567 - val_loss: 13.9183\n",
      "Epoch 290/2500\n",
      "40/40 - 2s - loss: 3.5252 - val_loss: 13.8455\n",
      "Epoch 291/2500\n",
      "40/40 - 2s - loss: 3.7978 - val_loss: 13.6519\n",
      "Epoch 292/2500\n",
      "40/40 - 2s - loss: 3.1016 - val_loss: 13.4430\n",
      "Epoch 293/2500\n",
      "40/40 - 2s - loss: 4.2349 - val_loss: 13.6577\n",
      "Epoch 294/2500\n",
      "40/40 - 2s - loss: 3.2242 - val_loss: 14.5316\n",
      "Epoch 295/2500\n",
      "40/40 - 2s - loss: 3.9589 - val_loss: 14.0460\n",
      "Epoch 296/2500\n",
      "40/40 - 2s - loss: 4.0466 - val_loss: 13.8951\n",
      "Epoch 297/2500\n",
      "40/40 - 2s - loss: 3.0137 - val_loss: 13.6301\n",
      "Epoch 298/2500\n",
      "40/40 - 2s - loss: 3.6146 - val_loss: 13.9609\n",
      "Epoch 299/2500\n",
      "40/40 - 2s - loss: 5.2655 - val_loss: 14.5238\n",
      "Epoch 300/2500\n",
      "40/40 - 2s - loss: 4.3533 - val_loss: 13.3743\n",
      "Epoch 301/2500\n",
      "40/40 - 2s - loss: 2.8931 - val_loss: 14.0174\n",
      "Epoch 302/2500\n",
      "40/40 - 2s - loss: 3.2249 - val_loss: 13.3564\n",
      "Epoch 303/2500\n",
      "40/40 - 2s - loss: 5.4011 - val_loss: 14.1196\n",
      "Epoch 304/2500\n",
      "40/40 - 2s - loss: 5.0958 - val_loss: 13.2242\n",
      "Epoch 305/2500\n",
      "40/40 - 2s - loss: 2.8438 - val_loss: 13.5289\n",
      "Epoch 306/2500\n",
      "40/40 - 2s - loss: 3.5179 - val_loss: 13.5319\n",
      "Epoch 307/2500\n",
      "40/40 - 2s - loss: 3.9927 - val_loss: 16.6240\n",
      "Epoch 308/2500\n",
      "40/40 - 2s - loss: 4.2739 - val_loss: 13.4847\n",
      "Epoch 309/2500\n",
      "40/40 - 2s - loss: 4.2403 - val_loss: 13.8080\n",
      "Epoch 310/2500\n",
      "40/40 - 2s - loss: 3.2140 - val_loss: 13.6035\n",
      "Epoch 311/2500\n",
      "40/40 - 2s - loss: 4.9601 - val_loss: 14.8996\n",
      "Epoch 312/2500\n",
      "40/40 - 2s - loss: 5.3072 - val_loss: 13.5089\n",
      "Epoch 313/2500\n",
      "40/40 - 2s - loss: 2.6292 - val_loss: 13.4469\n",
      "Epoch 314/2500\n",
      "40/40 - 2s - loss: 3.3329 - val_loss: 13.6413\n",
      "Epoch 315/2500\n",
      "40/40 - 2s - loss: 2.9248 - val_loss: 13.5608\n",
      "Epoch 316/2500\n",
      "40/40 - 2s - loss: 3.3375 - val_loss: 13.5625\n",
      "Epoch 317/2500\n",
      "40/40 - 2s - loss: 3.1785 - val_loss: 13.2721\n",
      "Epoch 318/2500\n",
      "40/40 - 2s - loss: 3.3727 - val_loss: 13.4386\n",
      "Epoch 319/2500\n",
      "40/40 - 2s - loss: 3.6225 - val_loss: 15.5868\n",
      "Epoch 320/2500\n",
      "40/40 - 2s - loss: 3.6438 - val_loss: 13.9038\n",
      "Epoch 321/2500\n",
      "40/40 - 2s - loss: 3.9992 - val_loss: 13.6471\n",
      "Epoch 322/2500\n",
      "40/40 - 2s - loss: 3.0337 - val_loss: 13.7846\n",
      "Epoch 323/2500\n",
      "40/40 - 2s - loss: 3.5742 - val_loss: 13.3970\n",
      "Epoch 324/2500\n",
      "40/40 - 2s - loss: 3.4750 - val_loss: 13.6463\n",
      "Epoch 325/2500\n",
      "40/40 - 2s - loss: 3.8269 - val_loss: 13.7649\n",
      "Epoch 326/2500\n",
      "40/40 - 2s - loss: 3.5086 - val_loss: 13.9621\n",
      "Epoch 327/2500\n",
      "40/40 - 2s - loss: 3.7232 - val_loss: 13.9285\n",
      "Epoch 328/2500\n",
      "40/40 - 2s - loss: 2.5801 - val_loss: 13.9373\n",
      "Epoch 329/2500\n",
      "40/40 - 2s - loss: 3.3487 - val_loss: 14.1233\n",
      "Epoch 330/2500\n",
      "40/40 - 2s - loss: 3.2706 - val_loss: 15.5484\n",
      "Epoch 331/2500\n",
      "40/40 - 2s - loss: 4.2652 - val_loss: 13.2418\n",
      "Epoch 332/2500\n",
      "40/40 - 2s - loss: 4.2894 - val_loss: 14.3387\n",
      "Epoch 333/2500\n",
      "40/40 - 2s - loss: 4.0281 - val_loss: 13.5805\n",
      "Epoch 334/2500\n",
      "40/40 - 2s - loss: 5.0179 - val_loss: 14.6647\n",
      "Epoch 335/2500\n",
      "40/40 - 2s - loss: 3.2597 - val_loss: 13.4360\n",
      "Epoch 336/2500\n",
      "40/40 - 2s - loss: 2.7726 - val_loss: 13.6099\n",
      "Epoch 337/2500\n",
      "40/40 - 2s - loss: 4.0379 - val_loss: 14.1353\n",
      "Epoch 338/2500\n",
      "40/40 - 2s - loss: 3.1865 - val_loss: 13.3217\n",
      "Epoch 339/2500\n",
      "40/40 - 2s - loss: 3.3607 - val_loss: 13.7955\n",
      "Epoch 340/2500\n",
      "40/40 - 2s - loss: 2.5841 - val_loss: 13.3042\n",
      "Epoch 341/2500\n",
      "40/40 - 2s - loss: 2.8563 - val_loss: 13.7579\n",
      "Epoch 342/2500\n",
      "40/40 - 2s - loss: 4.2316 - val_loss: 13.8162\n",
      "Epoch 343/2500\n",
      "40/40 - 2s - loss: 2.7478 - val_loss: 13.4901\n",
      "Epoch 344/2500\n",
      "40/40 - 2s - loss: 3.7917 - val_loss: 13.8629\n",
      "Epoch 345/2500\n",
      "40/40 - 2s - loss: 2.9734 - val_loss: 13.2822\n",
      "Epoch 346/2500\n",
      "40/40 - 2s - loss: 2.7598 - val_loss: 13.3925\n",
      "Epoch 347/2500\n",
      "40/40 - 2s - loss: 3.1963 - val_loss: 14.1429\n",
      "Epoch 348/2500\n",
      "40/40 - 2s - loss: 3.0760 - val_loss: 13.9371\n",
      "Epoch 349/2500\n",
      "40/40 - 2s - loss: 3.3683 - val_loss: 13.3612\n",
      "Epoch 350/2500\n",
      "40/40 - 2s - loss: 3.1353 - val_loss: 13.3595\n",
      "Epoch 351/2500\n",
      "40/40 - 2s - loss: 4.4109 - val_loss: 13.7449\n",
      "Epoch 352/2500\n",
      "40/40 - 2s - loss: 3.9527 - val_loss: 13.8404\n",
      "Epoch 353/2500\n",
      "40/40 - 2s - loss: 3.4341 - val_loss: 13.3922\n",
      "Epoch 354/2500\n",
      "40/40 - 2s - loss: 2.8414 - val_loss: 13.6967\n",
      "Epoch 355/2500\n",
      "40/40 - 2s - loss: 2.1997 - val_loss: 14.0889\n",
      "Epoch 356/2500\n",
      "40/40 - 2s - loss: 2.9651 - val_loss: 13.4696\n",
      "Epoch 357/2500\n",
      "40/40 - 2s - loss: 2.2047 - val_loss: 13.9722\n",
      "Epoch 358/2500\n",
      "40/40 - 2s - loss: 2.8075 - val_loss: 13.9644\n"
     ]
    }
   ],
   "source": [
    "new_fit = True\n",
    "\n",
    "if new_fit:\n",
    "    history = best_model.fit(X_training, Y_training, callbacks= my_callbacks,validation_data=(X_test, Y_test), epochs=2500,  batch_size=25, verbose=2 ) \n",
    "else:\n",
    "    best_model     =  keras.models.load_model(\"./ml_data/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-48b006c10972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "# summarize history for loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "#plt.xlim(50, 1000)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jan/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./ml_data/model/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"./ml_data/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
