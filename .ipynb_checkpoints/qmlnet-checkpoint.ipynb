{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'tutorial' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/qmlcode/tutorial.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jan/projects/qmlnet/tutorial\n",
      "exercise_2_1.py  exercise_2_4.py  modelnew.h5  QML_Tutorial.ipynb\n",
      "exercise_2_2.py  hof_qm7.txt\t  __pycache__  QML_Tutorial_sklearn.ipynb\n",
      "exercise_2_3.py  LICENSE\t  qm7\t       tutorial_data.py\n"
     ]
    }
   ],
   "source": [
    "%cd tutorial\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1633.28 -1212.67 -1531.73 ... -1728.7  -1506.76 -1866.88]\n",
      "[[1.         0.8152882  0.87350271 ... 0.90991951 0.82913994 0.77672171]\n",
      " [0.8152882  1.         0.81460855 ... 0.84226491 0.97323939 0.78838225]\n",
      " [0.87350271 0.81460855 1.         ... 0.8913725  0.83339596 0.78083487]\n",
      " ...\n",
      " [0.90991951 0.84226491 0.8913725  ... 1.         0.86685092 0.88326791]\n",
      " [0.82913994 0.97323939 0.83339596 ... 0.86685092 1.         0.80932061]\n",
      " [0.77672171 0.78838225 0.78083487 ... 0.88326791 0.80932061 1.        ]]\n",
      "15.00718369095469\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import qml\n",
    "from qml.kernels import gaussian_kernel\n",
    "from qml.math import cho_solve\n",
    "\n",
    "from tutorial_data import compounds\n",
    "from tutorial_data import energy_pbe0\n",
    "from tutorial_data import energy_delta\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # For every compound generate a coulomb matrix\n",
    "    for mol in compounds:\n",
    "\n",
    "        mol.generate_coulomb_matrix(size=23, sorting=\"row-norm\")\n",
    "        # mol.generate_bob(size=23, asize={\"O\":3, \"C\":7, \"N\":3, \"H\":16, \"S\":1})\n",
    "            \n",
    "\n",
    "    # Make a big 2D array with all the \n",
    "    X = np.array([mol.representation for mol in compounds], dtype=np.float32)\n",
    "    energy_pbe0 = np.array(energy_pbe0,  dtype=np.float32)\n",
    "    # X = np.array([mol.bob for mol in compounds])\n",
    "\n",
    "    print(energy_pbe0)\n",
    "\n",
    "    # Assign 1000 first molecules to the training set\n",
    "    X_training = X[:1000]\n",
    "    Y_training = energy_pbe0[:1000]\n",
    "\n",
    "    # Y_training = energy_delta[:1000]\n",
    "\n",
    "    # Assign 1000 first molecules to the training set\n",
    "    X_test = X[-1000:]\n",
    "    Y_test = energy_pbe0[-1000:]\n",
    "    # Y_test = energy_delta[-1000:]\n",
    "   \n",
    "    # Calculate the Gaussian kernel\n",
    "    sigma = 100 #700.0\n",
    "    K = gaussian_kernel(X_training, X_training, sigma)\n",
    "    print(K)\n",
    "\n",
    "    # Add a small lambda to the diagonal of the kernel matrix\n",
    "    K[np.diag_indices_from(K)] += 1e-8\n",
    "\n",
    "    # Use the built-in Cholesky-decomposition to solve\n",
    "    alpha = cho_solve(K, Y_training) \n",
    "\n",
    "    #print(alpha)\n",
    "\n",
    "    # Assign 1000 last molecules to the test set\n",
    "    X_test = X[-1000:]\n",
    "    Y_test = energy_pbe0[-1000:]\n",
    "\n",
    "    # calculate a kernel matrix between test and training data, using the same sigma\n",
    "    Ks = gaussian_kernel(X_test, X_training, sigma)\n",
    "\n",
    "    # Make the predictions\n",
    "    Y_predicted = np.dot(Ks, alpha)\n",
    "\n",
    "    # Calculate mean-absolute-error (MAE):\n",
    "    print(np.mean(np.abs(Y_predicted - Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Rep (Dense)            (None, 276)               76452     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              277000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "HL_1 (Dense)                 (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "HL_2 (Dense)                 (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "HL_3 (Dense)                 (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "HL_4 (Dense)                 (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "HL_5 (Dense)                 (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "HL_6 (Dense)                 (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "HL_7 (Dense)                 (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "Output_Energy (Dense)        (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 9,363,453\n",
      "Trainable params: 9,363,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5000\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 1409.2434 - val_loss: 1200.4390\n",
      "Epoch 2/5000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 757.5703 - val_loss: 121.9478\n",
      "Epoch 3/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 222.4574 - val_loss: 201.4346\n",
      "Epoch 4/5000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 140.9552 - val_loss: 119.5610\n",
      "Epoch 5/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 84.9366 - val_loss: 75.1919\n",
      "Epoch 6/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 65.6420 - val_loss: 57.5071\n",
      "Epoch 7/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 53.9203 - val_loss: 55.0666\n",
      "Epoch 8/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 46.5860 - val_loss: 45.1752\n",
      "Epoch 9/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 41.8237 - val_loss: 39.5230\n",
      "Epoch 10/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 37.4135 - val_loss: 37.2840\n",
      "Epoch 11/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 34.8251 - val_loss: 35.3728\n",
      "Epoch 12/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 33.3256 - val_loss: 34.2803\n",
      "Epoch 13/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 33.0025 - val_loss: 32.7109\n",
      "Epoch 14/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 27.9448 - val_loss: 29.6900\n",
      "Epoch 15/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 27.0139 - val_loss: 30.5165\n",
      "Epoch 16/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 25.9120 - val_loss: 28.6015\n",
      "Epoch 17/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 24.6576 - val_loss: 26.6859\n",
      "Epoch 18/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 23.6643 - val_loss: 27.1048\n",
      "Epoch 19/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 23.7540 - val_loss: 26.0686\n",
      "Epoch 20/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 22.4236 - val_loss: 25.3230\n",
      "Epoch 21/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 22.3012 - val_loss: 24.9171\n",
      "Epoch 22/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 21.0314 - val_loss: 24.2888\n",
      "Epoch 23/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 24.4633 - val_loss: 35.0256\n",
      "Epoch 24/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 27.7557 - val_loss: 26.0215\n",
      "Epoch 25/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 24.9643 - val_loss: 39.2897\n",
      "Epoch 26/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 30.6091 - val_loss: 32.0816\n",
      "Epoch 27/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 22.8501 - val_loss: 24.6175\n",
      "Epoch 28/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 21.9209 - val_loss: 25.2915\n",
      "Epoch 29/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 20.4593 - val_loss: 28.3064\n",
      "Epoch 30/5000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 20.8177 - val_loss: 23.1283\n",
      "Epoch 31/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 18.1206 - val_loss: 23.0303\n",
      "Epoch 32/5000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 17.5049 - val_loss: 22.6122\n",
      "Epoch 33/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.1235 - val_loss: 23.8222\n",
      "Epoch 34/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 17.1891 - val_loss: 22.4445\n",
      "Epoch 35/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.3790 - val_loss: 28.7167\n",
      "Epoch 36/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.9738 - val_loss: 29.0972\n",
      "Epoch 37/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 21.9129 - val_loss: 27.1543\n",
      "Epoch 38/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 18.2631 - val_loss: 23.6236\n",
      "Epoch 39/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.8707 - val_loss: 24.6703\n",
      "Epoch 40/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.2300 - val_loss: 28.1471\n",
      "Epoch 41/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 18.5523 - val_loss: 21.6031\n",
      "Epoch 42/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.0797 - val_loss: 22.0969\n",
      "Epoch 43/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 16.5149 - val_loss: 21.9257\n",
      "Epoch 44/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 15.9255 - val_loss: 22.3168\n",
      "Epoch 45/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 31.5670 - val_loss: 22.3210\n",
      "Epoch 46/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 24.9181 - val_loss: 29.0941\n",
      "Epoch 47/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 19.0630 - val_loss: 23.0385\n",
      "Epoch 48/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 14.9348 - val_loss: 21.5728\n",
      "Epoch 49/5000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 14.4300 - val_loss: 21.1065\n",
      "Epoch 50/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 13.5211 - val_loss: 21.7993\n",
      "Epoch 51/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.5179 - val_loss: 21.1189\n",
      "Epoch 52/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.5233 - val_loss: 36.1006\n",
      "Epoch 53/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 24.1948 - val_loss: 24.6953\n",
      "Epoch 54/5000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 22.7357 - val_loss: 35.4544\n",
      "Epoch 55/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 23.3758 - val_loss: 26.3804\n",
      "Epoch 56/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 17.9428 - val_loss: 23.2685\n",
      "Epoch 57/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 16.1995 - val_loss: 21.2642\n",
      "Epoch 58/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.7956 - val_loss: 22.5647\n",
      "Epoch 59/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 21.0620 - val_loss: 27.4350\n",
      "Epoch 60/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.0846 - val_loss: 24.2012\n",
      "Epoch 61/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 19.5991 - val_loss: 22.6757\n",
      "Epoch 62/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 13.7820 - val_loss: 20.6517\n",
      "Epoch 63/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 13.0783 - val_loss: 20.7987\n",
      "Epoch 64/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 14.1987 - val_loss: 23.9369\n",
      "Epoch 65/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 12.0119 - val_loss: 20.6023\n",
      "Epoch 66/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.0596 - val_loss: 21.2406\n",
      "Epoch 67/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.7838 - val_loss: 22.5827\n",
      "Epoch 68/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.5422 - val_loss: 20.9724\n",
      "Epoch 69/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 19.9954 - val_loss: 29.3797\n",
      "Epoch 70/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 18.3003 - val_loss: 28.1577\n",
      "Epoch 71/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.7390 - val_loss: 21.3986\n",
      "Epoch 72/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.8124 - val_loss: 21.7687\n",
      "Epoch 73/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 11.6540 - val_loss: 27.6058\n",
      "Epoch 74/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 19.9793 - val_loss: 24.8979\n",
      "Epoch 75/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 20.1691 - val_loss: 21.1623\n",
      "Epoch 76/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.7118 - val_loss: 21.9483\n",
      "Epoch 77/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.6916 - val_loss: 22.4294\n",
      "Epoch 78/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 16.9370 - val_loss: 31.1355\n",
      "Epoch 79/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 18.2866 - val_loss: 23.5892\n",
      "Epoch 80/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 18.2714 - val_loss: 22.1840\n",
      "Epoch 81/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 13.5801 - val_loss: 21.5865\n",
      "Epoch 82/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.1004 - val_loss: 21.0537\n",
      "Epoch 83/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.8530 - val_loss: 21.4585\n",
      "Epoch 84/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 16.0952 - val_loss: 28.5608\n",
      "Epoch 85/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 17.9971 - val_loss: 24.4514\n",
      "Epoch 86/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 18.2842 - val_loss: 21.8990\n",
      "Epoch 87/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.8209 - val_loss: 22.8470\n",
      "Epoch 88/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.0684 - val_loss: 23.8804\n",
      "Epoch 89/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.0838 - val_loss: 21.1542\n",
      "Epoch 90/5000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 10.9933 - val_loss: 20.3634\n",
      "Epoch 91/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.7771 - val_loss: 20.9322\n",
      "Epoch 92/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 13.7876 - val_loss: 21.4336\n",
      "Epoch 93/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.7266 - val_loss: 22.6799\n",
      "Epoch 94/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 16.6172 - val_loss: 23.7496\n",
      "Epoch 95/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.2432 - val_loss: 23.3687\n",
      "Epoch 96/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 15.6962 - val_loss: 21.1060\n",
      "Epoch 97/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.2668 - val_loss: 22.6435\n",
      "Epoch 98/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.2995 - val_loss: 24.1732\n",
      "Epoch 99/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.1126 - val_loss: 20.6727\n",
      "Epoch 100/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 14.7508 - val_loss: 21.2602\n",
      "Epoch 101/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.8658 - val_loss: 26.7797\n",
      "Epoch 102/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 15.2003 - val_loss: 20.8555\n",
      "Epoch 103/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.9942 - val_loss: 21.0901\n",
      "Epoch 104/5000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 9.8300 - val_loss: 19.8553\n",
      "Epoch 105/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 9.5094 - val_loss: 19.7033\n",
      "Epoch 106/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.5003 - val_loss: 21.7633\n",
      "Epoch 107/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 8.5742 - val_loss: 19.8275\n",
      "Epoch 108/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 7.7689 - val_loss: 19.7789\n",
      "Epoch 109/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.0539 - val_loss: 20.0886\n",
      "Epoch 110/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.3931 - val_loss: 19.7256\n",
      "Epoch 111/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.0681 - val_loss: 20.0218\n",
      "Epoch 112/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.3086 - val_loss: 20.0090\n",
      "Epoch 113/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.8262 - val_loss: 33.5280\n",
      "Epoch 114/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.8901 - val_loss: 26.6341\n",
      "Epoch 115/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 13.3363 - val_loss: 27.4829\n",
      "Epoch 116/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 16.4556 - val_loss: 26.2129\n",
      "Epoch 117/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 16.1605 - val_loss: 23.7550\n",
      "Epoch 118/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.0259 - val_loss: 19.9238\n",
      "Epoch 119/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.6969 - val_loss: 19.8343\n",
      "Epoch 120/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.5299 - val_loss: 22.7203\n",
      "Epoch 121/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 10.2742 - val_loss: 21.1548\n",
      "Epoch 122/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.4266 - val_loss: 19.9652\n",
      "Epoch 123/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 15.3936 - val_loss: 20.9955\n",
      "Epoch 124/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.0681 - val_loss: 21.1758\n",
      "Epoch 125/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.1484 - val_loss: 20.1782\n",
      "Epoch 126/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.1640 - val_loss: 20.4673\n",
      "Epoch 127/5000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 10.4527 - val_loss: 19.6973\n",
      "Epoch 128/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 8.4170 - val_loss: 19.9356\n",
      "Epoch 129/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 8.4020 - val_loss: 20.2078\n",
      "Epoch 130/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.3614 - val_loss: 19.8111\n",
      "Epoch 131/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.2801 - val_loss: 21.2658\n",
      "Epoch 132/5000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 7.8123 - val_loss: 19.5200\n",
      "Epoch 133/5000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 7.8370 - val_loss: 19.3748\n",
      "Epoch 134/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 7.9396 - val_loss: 20.4790\n",
      "Epoch 135/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 13.6863 - val_loss: 27.9443\n",
      "Epoch 136/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 16.3895 - val_loss: 22.6794\n",
      "Epoch 137/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 14.4561 - val_loss: 33.0593\n",
      "Epoch 138/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 19.3577 - val_loss: 23.0252\n",
      "Epoch 139/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 19.3466 - val_loss: 23.1783\n",
      "Epoch 140/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 10.1204 - val_loss: 19.9894\n",
      "Epoch 141/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 14.4925 - val_loss: 20.4526\n",
      "Epoch 142/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 14.8108 - val_loss: 20.8004\n",
      "Epoch 143/5000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 11.1616 - val_loss: 19.8860\n",
      "Epoch 144/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.9563 - val_loss: 19.6148\n",
      "Epoch 145/5000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 13.9200 - val_loss: 21.8003\n",
      "Epoch 146/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.1565 - val_loss: 21.6096\n",
      "Epoch 147/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 14.5998 - val_loss: 21.2066\n",
      "Epoch 148/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 15.1893 - val_loss: 21.5658\n",
      "Epoch 149/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 8.0548 - val_loss: 20.0874\n",
      "Epoch 150/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 7.9712 - val_loss: 19.5519\n",
      "Epoch 151/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 8.1876 - val_loss: 21.7382\n",
      "Epoch 152/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.3742 - val_loss: 22.4885\n",
      "Epoch 153/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 8.2534 - val_loss: 21.2116\n",
      "Epoch 154/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 8.1328 - val_loss: 20.9431\n",
      "Epoch 155/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 7.4878 - val_loss: 20.0680\n",
      "Epoch 156/5000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 7.9393 - val_loss: 19.3189\n",
      "Epoch 157/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.9079 - val_loss: 19.6274\n",
      "Epoch 158/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 7.8791 - val_loss: 20.9122\n",
      "Epoch 159/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.0585 - val_loss: 30.8942\n",
      "Epoch 160/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 17.5423 - val_loss: 19.8398\n",
      "Epoch 161/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 14.6454 - val_loss: 21.8890\n",
      "Epoch 162/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 14.7970 - val_loss: 22.9099\n",
      "Epoch 163/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 8.5643 - val_loss: 20.1948\n",
      "Epoch 164/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 6.5193 - val_loss: 19.6709\n",
      "Epoch 165/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 7.7588 - val_loss: 21.7080\n",
      "Epoch 166/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 10.9684 - val_loss: 20.1962\n",
      "Epoch 167/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.7120 - val_loss: 19.4663\n",
      "Epoch 168/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.0835 - val_loss: 19.3215\n",
      "Epoch 169/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.9597 - val_loss: 19.6495\n",
      "Epoch 170/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 8.3725 - val_loss: 20.1195\n",
      "Epoch 171/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.9433 - val_loss: 20.5801\n",
      "Epoch 172/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 7.8338 - val_loss: 22.2433\n",
      "Epoch 173/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.7298 - val_loss: 23.9643\n",
      "Epoch 174/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.1240 - val_loss: 19.9609\n",
      "Epoch 175/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.0648 - val_loss: 22.2800\n",
      "Epoch 176/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.4405 - val_loss: 22.9925\n",
      "Epoch 177/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 18.1826 - val_loss: 50.5999\n",
      "Epoch 178/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 29.0770 - val_loss: 23.7255\n",
      "Epoch 179/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 25.0960 - val_loss: 30.0972\n",
      "Epoch 180/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 19.5333 - val_loss: 21.3017\n",
      "Epoch 181/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 14.2060 - val_loss: 21.5907\n",
      "Epoch 182/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 12.6113 - val_loss: 21.2053\n",
      "Epoch 183/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.1792 - val_loss: 20.0276\n",
      "Epoch 184/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 8.5345 - val_loss: 20.1663\n",
      "Epoch 185/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 7.0991 - val_loss: 19.4459\n",
      "Epoch 186/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 7.8204 - val_loss: 20.7692\n",
      "Epoch 187/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.6525 - val_loss: 20.7055\n",
      "Epoch 188/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 7.3426 - val_loss: 19.7441\n",
      "Epoch 189/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 14.6183 - val_loss: 28.0553\n",
      "Epoch 190/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.3731 - val_loss: 20.2924\n",
      "Epoch 191/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.1080 - val_loss: 22.9145\n",
      "Epoch 192/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 10.8579 - val_loss: 27.0715\n",
      "Epoch 193/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.6637 - val_loss: 19.4037\n",
      "Epoch 194/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 5.7922 - val_loss: 21.2126\n",
      "Epoch 195/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 7.8484 - val_loss: 19.7337\n",
      "Epoch 196/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.7461 - val_loss: 20.3648\n",
      "Epoch 197/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.2308 - val_loss: 29.0106\n",
      "Epoch 198/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 17.8698 - val_loss: 24.9633\n",
      "Epoch 199/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.3730 - val_loss: 19.4045\n",
      "Epoch 200/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 5.2234 - val_loss: 19.5209\n",
      "Epoch 201/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 6.1811 - val_loss: 19.9511\n",
      "Epoch 202/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 6.0268 - val_loss: 19.9081\n",
      "Epoch 203/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 6.4161 - val_loss: 19.7846\n",
      "Epoch 204/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.5480 - val_loss: 23.5661\n",
      "Epoch 205/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 17.5374 - val_loss: 31.3686\n",
      "Epoch 206/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.2701 - val_loss: 25.2908\n",
      "Epoch 207/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 14.0353 - val_loss: 21.8143\n",
      "Epoch 208/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 14.5202 - val_loss: 21.5655\n",
      "Epoch 209/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 11.7167 - val_loss: 25.9738\n",
      "Epoch 210/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 15.5085 - val_loss: 22.1138\n",
      "Epoch 211/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.4050 - val_loss: 23.0715\n",
      "Epoch 212/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.9210 - val_loss: 20.4070\n",
      "Epoch 213/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.4710 - val_loss: 20.6412\n",
      "Epoch 214/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.9889 - val_loss: 21.2717\n",
      "Epoch 215/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.8034 - val_loss: 21.4839\n",
      "Epoch 216/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.1153 - val_loss: 20.0294\n",
      "Epoch 217/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.5046 - val_loss: 24.6935\n",
      "Epoch 218/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.3200 - val_loss: 20.6099\n",
      "Epoch 219/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.6922 - val_loss: 20.9144\n",
      "Epoch 220/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.3486 - val_loss: 19.6045\n",
      "Epoch 221/5000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 6.6252 - val_loss: 19.1959\n",
      "Epoch 222/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.3513 - val_loss: 19.4653\n",
      "Epoch 223/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 25.9706 - val_loss: 19.9914\n",
      "Epoch 224/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 21.6700 - val_loss: 31.3909\n",
      "Epoch 225/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 23.7925 - val_loss: 38.1067\n",
      "Epoch 226/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 22.1728 - val_loss: 21.8295\n",
      "Epoch 227/5000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 18.2899 - val_loss: 23.8899\n",
      "Epoch 228/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.5536 - val_loss: 24.6499\n",
      "Epoch 229/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.1407 - val_loss: 21.8633\n",
      "Epoch 230/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.2571 - val_loss: 21.3452\n",
      "Epoch 231/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.8296 - val_loss: 20.2286\n",
      "Epoch 232/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.0879 - val_loss: 19.2271\n",
      "Epoch 233/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 8.4164 - val_loss: 21.3233\n",
      "Epoch 234/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 10.6062 - val_loss: 19.5480\n",
      "Epoch 235/5000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 7.7936 - val_loss: 19.1006\n",
      "Epoch 236/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 5.8837 - val_loss: 19.4273\n",
      "Epoch 237/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 6.0280 - val_loss: 20.2077\n",
      "Epoch 238/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 7.1072 - val_loss: 19.2191\n",
      "Epoch 239/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.3887 - val_loss: 30.1705\n",
      "Epoch 240/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 23.1684 - val_loss: 27.5071\n",
      "Epoch 241/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 19.4793 - val_loss: 30.5615\n",
      "Epoch 242/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 22.0227 - val_loss: 27.9611\n",
      "Epoch 243/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 14.4985 - val_loss: 23.5605\n",
      "Epoch 244/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.7165 - val_loss: 19.4329\n",
      "Epoch 245/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.7381 - val_loss: 19.4553\n",
      "Epoch 246/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.3509 - val_loss: 33.4182\n",
      "Epoch 247/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 23.9372 - val_loss: 27.2661\n",
      "Epoch 248/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 16.4844 - val_loss: 25.6163\n",
      "Epoch 249/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.3186 - val_loss: 19.8360\n",
      "Epoch 250/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 7.3694 - val_loss: 19.6128\n",
      "Epoch 251/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 5.7019 - val_loss: 20.0190\n",
      "Epoch 252/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 5.8654 - val_loss: 19.3581\n",
      "Epoch 253/5000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 5.4708 - val_loss: 19.0884\n",
      "Epoch 254/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 5.1558 - val_loss: 19.6546\n",
      "Epoch 255/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4.9968 - val_loss: 19.7169\n",
      "Epoch 256/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 5.0177 - val_loss: 19.1454\n",
      "Epoch 257/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 6.2350 - val_loss: 21.6659\n",
      "Epoch 258/5000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 8.5445 - val_loss: 27.4312\n",
      "Epoch 259/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.0905 - val_loss: 19.2281\n",
      "Epoch 260/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 4.9552 - val_loss: 19.2246\n",
      "Epoch 261/5000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 6.3573 - val_loss: 24.8916\n",
      "Epoch 262/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.6069 - val_loss: 21.7101\n",
      "Epoch 263/5000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.7042 - val_loss: 20.1662\n",
      "Epoch 264/5000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 7.7097"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-81129eaedf6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0mcheckpoint_cb\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modelnew.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0mhistory\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import (Input, Convolution1D, Dense, MaxPooling1D,MaxPooling2D,\n",
    "                                    Flatten, Dropout, Activation, average,\n",
    "                                    BatchNormalization, Reshape, Conv2D)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#exponential_layer = keras.layers.Lambda(lambda x: tf.exp(-x**2.0))\n",
    "\n",
    "logdir = \"logs3/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(276, input_dim=276, kernel_initializer='normal', activation='linear', name='Input_Rep'))\n",
    "#276 = 12 x 23 \n",
    "BatchNormalization()\n",
    "Reshape((12, 23, 1), input_shape=(276,))\n",
    "Conv2D(64, 7, activation = 'selu', padding = 'same', input_shape= [12, 23, 1] ),\n",
    "MaxPooling2D(2)\n",
    "Conv2D(128, 5, activation = 'selu', padding = 'same' ),\n",
    "Conv2D(128, 5, activation = 'selu', padding = 'same' ),\n",
    "MaxPooling2D(2)\n",
    "Conv2D(256, 4, activation = 'selu', padding = 'same' ),\n",
    "Conv2D(256, 4, activation = 'selu', padding = 'same' ),\n",
    "MaxPooling2D(2)\n",
    "Conv2D(256*2, 3, activation = 'selu', padding = 'same' ),\n",
    "Conv2D(256*2, 3, activation = 'selu', padding = 'same' ),\n",
    "MaxPooling2D(2)\n",
    "\"\"\"\n",
    "Conv2D(256*2*2, 3, activation = 'selu', padding = 'same' ),\n",
    "Conv2D(256*2*2, 3, activation = 'selu', padding = 'same' ),\n",
    "MaxPooling2D(2)\n",
    "Conv2D(256*2*2*2, 3, activation = 'selu', padding = 'same' ),\n",
    "Conv2D(256*2*2*2, 3, activation = 'selu', padding = 'same' ),\n",
    "MaxPooling2D(2)\n",
    "\"\"\"\n",
    "\n",
    "Flatten()\n",
    "BatchNormalization()\n",
    "#model.add(exponential_layer)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.8)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.5)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.5)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu', name='HL_1'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.4)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu', name='HL_2'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.3)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu', name='HL_3'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.2)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu', name='HL_4'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.1)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu', name='HL_5'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.1)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='selu', name='HL_6'))\n",
    "BatchNormalization()\n",
    "#Dropout(rate=0.1)\n",
    "model.add(Dense(1000, kernel_initializer='he_normal', activation='linear', name='HL_7'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='linear', name='Output_Energy'))\n",
    "\n",
    "opt = Adam(lr=0.00005, decay=1e-5)  #with mae\n",
    "#opt = Adam(lr=0.0005, decay=1e-5)  #with mse\n",
    "\n",
    "\n",
    "model.compile(loss='mae', optimizer=opt)\n",
    "model.summary()\n",
    "\n",
    "new_fit = True\n",
    "\n",
    "transform = True\n",
    "if transform:\n",
    "  scaler = QuantileTransformer()\n",
    "  X_training  = tf.convert_to_tensor(scaler.fit_transform(X_training))\n",
    "  X_test      = tf.convert_to_tensor(scaler.transform(X_test))\n",
    "\n",
    "  Y_training = tf.convert_to_tensor(Y_training)\n",
    "  Y_test = tf.convert_to_tensor(Y_test)\n",
    "\n",
    "\n",
    "if new_fit:\n",
    "  checkpoint_cb  = keras.callbacks.ModelCheckpoint(\"modelnew.h5\", save_best_only=True)\n",
    "  history   = model.fit(X_training, Y_training, validation_data=(X_test, Y_test),batch_size=100, epochs=5000, callbacks=[ checkpoint_cb],verbose=1)\n",
    "\n",
    "else:\n",
    "  model = keras.models.load_model('modelnew.h5')  \n",
    "\n",
    "\n",
    "best = model #rnd_seawefwefwef_cv.bestefefimator_\n",
    "pred = best.predict(X_test)\n",
    "pred = pred.flatten()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(pred, Y_test, \"+\")\n",
    "plt.hist(np.abs(pred - np.array(Y_test)))\n",
    "plt.show()\n",
    "np.mean(np.abs(pred - Y_test))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(50, 1000)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPSklEQVR4nO3db4xdeV3H8feHFpd/Elp32pS2cdakUbpEds2krq4xSNEtLKH7ZJMSMU3cpE9qXAwJtvLA8KBJiYbgA1fTANLIn6bhj9vsRqQpEGKiW2Zhhe2W2pGu7di6HSAIaFLo8vXBPY2XdqZzO3967/x8v5LJOed3f+eez0zmfnr2zL1nU1VIktrykmEHkCQtPctdkhpkuUtSgyx3SWqQ5S5JDVo97AAAd955Z42Pjw87hiStKE8//fS3q2pstsdGotzHx8eZnJwcdgxJWlGS/Ptcj3lZRpIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGjQSn1BdrPF9Tw7luM8ffHAox5Wk+XjmLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNWigck/yfJJvJHkmyWQ3tjbJ8SRnu+Wavvn7k0wlOZPkgeUKL0ma3a2cuf9WVd1TVRPd9j7gRFVtAU502yTZCuwC7gZ2AI8lWbWEmSVJ81jMZZmdwOFu/TDwUN/4kaq6UlXngClg2yKOI0m6RYOWewGfT/J0kj3d2PqqugTQLdd14xuBC337TndjPyXJniSTSSZnZmYWll6SNKtB7+d+f1VdTLIOOJ7kmzeZm1nG6oaBqkPAIYCJiYkbHpckLdxAZ+5VdbFbXgY+S+8yywtJNgB0y8vd9Glgc9/um4CLSxVYkjS/ecs9ySuT/Oy1deB3gGeBY8Dubtpu4PFu/RiwK8kdSe4CtgAnlzq4JGlug1yWWQ98Nsm1+Z+oqs8l+QpwNMkjwHngYYCqOpXkKPAccBXYW1UvLkt6SdKs5i33qvoW8IZZxr8DbJ9jnwPAgUWnkyQtiJ9QlaQGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ0auNyTrErytSRPdNtrkxxPcrZbrumbuz/JVJIzSR5YjuCSpLndypn7o8Dpvu19wImq2gKc6LZJshXYBdwN7AAeS7JqaeJKkgYxULkn2QQ8CHyob3gncLhbPww81Dd+pKquVNU5YArYtiRpJUkDGfTM/YPAe4Cf9I2tr6pLAN1yXTe+EbjQN2+6G/spSfYkmUwyOTMzc6u5JUk3MW+5J3kbcLmqnh7wOTPLWN0wUHWoqiaqamJsbGzAp5YkDWL1AHPuB96e5K3Ay4BXJ/kY8EKSDVV1KckG4HI3fxrY3Lf/JuDiUoaWJN3cvGfuVbW/qjZV1Ti9P5R+oareCRwDdnfTdgOPd+vHgF1J7khyF7AFOLnkySVJcxrkzH0uB4GjSR4BzgMPA1TVqSRHgeeAq8Deqnpx0UklSQO7pXKvqi8BX+rWvwNsn2PeAeDAIrNJkhbIT6hKUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDVo3nJP8rIkJ5P8S5JTSd7Xja9NcjzJ2W65pm+f/UmmkpxJ8sByfgOSpBsNcuZ+BXhTVb0BuAfYkeQ+YB9woqq2ACe6bZJsBXYBdwM7gMeSrFqG7JKkOcxb7tXzw27zpd1XATuBw934YeChbn0ncKSqrlTVOWAK2LaUoSVJNzfQNfckq5I8A1wGjlfVU8D6qroE0C3XddM3Ahf6dp/uxq5/zj1JJpNMzszMLOJbkCRdb6Byr6oXq+oeYBOwLcnrbzI9sz3FLM95qKomqmpibGxsoLCSpMHc0rtlqup7wJfoXUt/IckGgG55uZs2DWzu220TcHGxQSVJg1s934QkY8CPq+p7SV4OvBl4P3AM2A0c7JaPd7scAz6R5APAa4EtwMllyD504/ueHMpxnz/44FCOK2nlmLfcgQ3A4e4dLy8BjlbVE0n+CTia5BHgPPAwQFWdSnIUeA64CuytqheXJ74kaTbzlntVfR24d5bx7wDb59jnAHBg0ekkSQviJ1QlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkho0b7kn2Zzki0lOJzmV5NFufG2S40nOdss1ffvsTzKV5EySB5bzG5Ak3WiQM/erwLur6nXAfcDeJFuBfcCJqtoCnOi26R7bBdwN7AAeS7JqOcJLkmY3b7lX1aWq+mq3/gPgNLAR2Akc7qYdBh7q1ncCR6rqSlWdA6aAbUucW5J0E7d0zT3JOHAv8BSwvqouQe8fAGBdN20jcKFvt+lu7Prn2pNkMsnkzMzMAqJLkuYycLkneRXwaeBdVfX9m02dZaxuGKg6VFUTVTUxNjY2aAxJ0gAGKvckL6VX7B+vqs90wy8k2dA9vgG43I1PA5v7dt8EXFyauJKkQQzybpkAHwZOV9UH+h46Buzu1ncDj/eN70pyR5K7gC3AyaWLLEmaz+oB5twP/B7wjSTPdGN/AhwEjiZ5BDgPPAxQVaeSHAWeo/dOm71V9eJSB5ckzW3ecq+qf2T26+gA2+fY5wBwYBG5JEmL4CdUJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1KDVww6gWze+78mhHfv5gw8O7diSBjfvmXuSjyS5nOTZvrG1SY4nOdst1/Q9tj/JVJIzSR5YruCSpLkNclnmo8CO68b2ASeqagtwotsmyVZgF3B3t89jSVYtWVpJ0kDmLfeq+jLw3euGdwKHu/XDwEN940eq6kpVnQOmgG1LE1WSNKiF/kF1fVVdAuiW67rxjcCFvnnT3Zgk6TZa6nfLZJaxmnVisifJZJLJmZmZJY4hSf+/LbTcX0iyAaBbXu7Gp4HNffM2ARdne4KqOlRVE1U1MTY2tsAYkqTZLLTcjwG7u/XdwON947uS3JHkLmALcHJxESVJt2re97kn+STwRuDOJNPAnwIHgaNJHgHOAw8DVNWpJEeB54CrwN6qenGZskuS5jBvuVfVO+Z4aPsc8w8ABxYTSpK0ON5+QJIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWrQvP8PVanf+L4nh3Lc5w8+OJTjSiuVZ+6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgP6GqFWFYn4wFPx2rlWnZztyT7EhyJslUkn3LdRxJ0o2W5cw9ySrgL4HfBqaBryQ5VlXPLcfxpOXk/XS0Ei3XZZltwFRVfQsgyRFgJ2C5SwPyUtTt0+LPernKfSNwoW97GvjV/glJ9gB7us0fJjmzwGPdCXx7gfsOk7lvL3Pfgrx/0U/hz3tAi/xZ//xcDyxXuWeWsfqpjapDwKFFHyiZrKqJxT7P7Wbu28vct5e5h2+5/qA6DWzu294EXFymY0mSrrNc5f4VYEuSu5L8DLALOLZMx5IkXWdZLstU1dUkfwD8A7AK+EhVnVqOY7EEl3aGxNy3l7lvL3MPWapq/lmSpBXF2w9IUoMsd0lq0Iou95Vyi4Mkm5N8McnpJKeSPNqNr01yPMnZbrlm2Fmvl2RVkq8leaLbHvnMAElek+RTSb7Z/dx/bdSzJ/mj7vfj2SSfTPKyUc2c5CNJLid5tm9szqxJ9nev0zNJHhihzH/W/Y58Pclnk7xmlDIvxoot975bHLwF2Aq8I8nW4aaa01Xg3VX1OuA+YG+XdR9woqq2ACe67VHzKHC6b3slZAb4C+BzVfVLwBvofQ8jmz3JRuAPgYmqej29NyLsYnQzfxTYcd3YrFm73/VdwN3dPo91r9/b7aPcmPk48Pqq+mXgX4H9MFKZF2zFljt9tzioqh8B125xMHKq6lJVfbVb/wG9otlIL+/hbtph4KGhBJxDkk3Ag8CH+oZHOjNAklcDvwl8GKCqflRV32P0s68GXp5kNfAKep8NGcnMVfVl4LvXDc+VdSdwpKquVNU5YIre6/e2mi1zVX2+qq52m/9M7zM5MCKZF2Mll/tstzjYOKQsA0syDtwLPAWsr6pL0PsHAFg3xGiz+SDwHuAnfWOjnhngF4AZ4G+6S0ofSvJKRjh7Vf0H8OfAeeAS8F9V9XlGOPMs5sq6Ul6rvw/8fbe+UjLPaSWX+7y3OBg1SV4FfBp4V1V9f9h5bibJ24DLVfX0sLMswGrgV4C/qqp7gf9mdC5nzKq7Pr0TuAt4LfDKJO8cbqolM/Kv1STvpXf59OPXhmaZNlKZ57OSy31F3eIgyUvpFfvHq+oz3fALSTZ0j28ALg8r3yzuB96e5Hl6l7zelORjjHbma6aB6ap6qtv+FL2yH+XsbwbOVdVMVf0Y+Azw64x25uvNlXWkX6tJdgNvA363/u+DPyOdeRArudxXzC0OkoTe9d/TVfWBvoeOAbu79d3A47c721yqan9VbaqqcXo/2y9U1TsZ4czXVNV/AheS/GI3tJ3e7aZHOft54L4kr+h+X7bT+9vMKGe+3lxZjwG7ktyR5C5gC3ByCPlukGQH8MfA26vqf/oeGtnMA6uqFfsFvJXeX7j/DXjvsPPcJOdv0PtPuq8Dz3RfbwV+jt67Cs52y7XDzjpH/jcCT3TrKyXzPcBk9zP/O2DNqGcH3gd8E3gW+FvgjlHNDHyS3t8GfkzvLPeRm2UF3tu9Ts8AbxmhzFP0rq1fe13+9ShlXsyXtx+QpAat5MsykqQ5WO6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQf8L3r3WEm+4sGQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15.637714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = model #rnd_search_cv.best_estimator_\n",
    "pred = best.predict(X_test)\n",
    "pred = pred.flatten()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(pred, Y_test, \"+\")\n",
    "plt.hist(np.abs(pred - np.array(Y_test)))\n",
    "plt.show()\n",
    "np.mean(np.abs(pred - Y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [00:59<00:00, 16.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "mc_predictions = []\n",
    "for i in tqdm.tqdm(range(1000)):\n",
    "    y_p = best(X_test, training=True)\n",
    "    mc_predictions.append(y_p)\n",
    "    \n",
    "mc_predictions = np.array(mc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_ensemble_pred = np.array(mc_predictions).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15.637552"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_ensemble_pred\n",
    "\n",
    "\n",
    "plt.hist(np.abs(mc_ensemble_pred.flatten() - np.array(Y_test)))\n",
    "plt.show()\n",
    "np.mean(np.abs(mc_ensemble_pred.flatten() - Y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
